{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "k = 160\n",
    "alpha = 8e-4\n",
    "l2_lambda = 0.01 # Regularization for the Item (Movie) Latent Component\n",
    "l2_mu = 0.01 # Regularization for the User Latent Component\n",
    "epochs = 1000\n",
    "epochs_list = [225, 250, 275, 300, 325, 350, 375, 400]\n",
    "momentum = 0.1\n",
    "# patience = 10  # Number of epochs to wait for improvement before stopping\n",
    "# tolerance = 1e-4  # Minimum improvement threshold\n",
    "\n",
    "#blows up with 1e-1, 1e-2\n",
    "alpha_list = [1e-3, 8e-4, 5e-4]\n",
    "k_list = [90, 100, 110, 120, 130, 140, 150, 160]\n",
    "mu_list = [0.01, 0.005, 0.001]\n",
    "lambda_list = [0.01, 0.005, 0.001]\n",
    "RMSE_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]]\n",
      "[[4.35211268 4.35211268 4.35211268 ... 4.35211268 4.35211268 4.35211268]\n",
      " [3.92857143 3.92857143 3.92857143 ... 3.92857143 3.92857143 3.92857143]\n",
      " [1.57692308 1.57692308 1.57692308 ... 1.57692308 1.57692308 1.57692308]\n",
      " ...\n",
      " [3.05576208 3.05576208 3.05576208 ... 3.05576208 3.05576208 3.05576208]\n",
      " [3.4375     3.4375     3.4375     ... 3.4375     3.4375     3.4375    ]\n",
      " [3.7414248  3.7414248  3.7414248  ... 3.7414248  3.7414248  3.7414248 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/t0f_b8n152d3c4c7jj83pf0w0000gn/T/ipykernel_95524/1118610029.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  tensor = np.array(torch.load('tensor.pth'))\n"
     ]
    }
   ],
   "source": [
    "# Ratings Matrix\n",
    "\n",
    "# I'll stick to how the data was provided and use a different convention than\n",
    "# the one used in class.\n",
    "# Users will be on the rows of the matrix and items (in this case, movies) as\n",
    "# columns.\n",
    "R = np.load('ratings_train.npy')\n",
    "R_test = np.load('ratings_test.npy')\n",
    "# tensor = np.array(torch.load('tensor.pth'))\n",
    "# users = []\n",
    "# for user in R:\n",
    "    \n",
    "#     use = user[~np.isnan(user)]\n",
    "#     user = [np.mean(use)] * len(tensor[0])\n",
    "    \n",
    "#     users.append(user)\n",
    "# users = np.array(users)\n",
    "# #print(np.shape(tensor))\n",
    "# print(tensor)\n",
    "# print(users)\n",
    "#print(R_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 4980\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of R Matrix\n",
    "m, n = R.shape\n",
    "#610 k 4980 k\n",
    "#610 k \n",
    "print(m, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of User-Movie pairs with no ratings\n",
    "S = np.isnan(R)\n",
    "S_train_finite = np.isfinite(R)\n",
    "S_test_finite = np.isfinite(R_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing User and Item Latent Component (U and I Matrices)\n",
    "# To incorporate biases, it's easier to simply add to columns to both matrices,\n",
    "# and the last column with 1s.\n",
    "if k != 0:\n",
    "    sd = 1/k\n",
    "\n",
    "    U = np.random.normal(scale=sd, size=(m, k+2))\n",
    "    I = np.random.normal(scale=sd, size=(n, k+2))\n",
    "    I = tensor\n",
    "    \n",
    "    # Initialize momentum terms (velocities) for U and V\n",
    "    v_U = np.zeros_like(U)\n",
    "    v_I = np.zeros_like(I)\n",
    "\n",
    "else:\n",
    "    U = np.random.random(size=(m, k_dim))\n",
    "    I = np.random.random(size=(n, k_dim))\n",
    "\n",
    "U[:, -1] = 1\n",
    "I[:, -2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(pred, target, mask):\n",
    "    pred2 = pred[mask]\n",
    "    target2 = target[mask]\n",
    "    \n",
    "    return np.sqrt(np.mean((pred2 - target2)**2))\n",
    "\n",
    "def accuracy(pred, target):\n",
    "    \n",
    "    return np.sum(np.equal(pred, target)) / np.size(pred)\n",
    "\n",
    "def round_to_nearest_half(matrix):\n",
    "    return np.ceil(matrix * 2) / 2\n",
    "\n",
    "def fit_distribution(predicted_R, R):\n",
    "    # Assume U, V are the factor matrices from matrix factorization\n",
    "   \n",
    "    \n",
    "    # Calculate mean and std of observed non-zero values in R\n",
    "    R_values = R.flatten()\n",
    "   \n",
    "    mean_R, std_R = np.mean(R_values), np.std(R_values)\n",
    "    \n",
    "    # Calculate mean and std of predicted values in predicted_R\n",
    "    predicted_R_values = predicted_R.flatten()\n",
    "    mean_pred, std_pred = np.mean(predicted_R_values), np.std(predicted_R_values)\n",
    "    \n",
    "    # Scale and shift to align the predicted mean and std with the observed ones\n",
    "    scaled_predicted_R = ((predicted_R - mean_pred) / std_pred) * std_R + mean_R\n",
    "\n",
    "    # Apply further regularization if needed, e.g., by clipping or binned transformation\n",
    "    scaled_predicted_R = np.clip(scaled_predicted_R, np.min(R_values), np.max(R_values))\n",
    "    \n",
    "    return scaled_predicted_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #hyperparameter training\n",
    "\n",
    "# hyperparameter1 = alpha_list\n",
    "# hyperparameter2 = k_list\n",
    "# hyperparameter3 = epochs_list\n",
    "# RMSE_list = []\n",
    "# for ia in hyperparameter1:\n",
    "    \n",
    "#     for ib in hyperparameter2:\n",
    "#         for ic in hyperparameter3:\n",
    "#             # l2_mu = ia\n",
    "#             # l2_lambda = ib\n",
    "#             alpha = ia\n",
    "#             k = ib\n",
    "#             sd = 1/k\n",
    "#             U = np.random.normal(scale=sd, size=(m, k+2))\n",
    "#             I = np.random.normal(scale=sd, size=(n, k+2))\n",
    "#             v_U = np.zeros_like(U)\n",
    "#             v_I = np.zeros_like(I)\n",
    "#             U[:, -1] = 1\n",
    "#             I[:, -2] = 1\n",
    "            \n",
    "#             losses = []\n",
    "#             # Initialize variables for early stopping\n",
    "#             best_validation_loss = float('inf')\n",
    "#             epochs_without_improvement = 0\n",
    "#             epochs = ic\n",
    "#             for _ in tqdm(range(epochs)):\n",
    "#                 # Setting entries with no ratings to zero\n",
    "#                 Rhat = np.dot(U, I.T)\n",
    "#                 Rhat[S] = 0\n",
    "            \n",
    "#                 E = np.nan_to_num(R) - Rhat\n",
    "            \n",
    "#                 # Loss\n",
    "#                 loss = np.sqrt(np.linalg.norm(E, 'fro'))\n",
    "#                 losses.append(loss)\n",
    "#                 #print(loss)\n",
    "            \n",
    "#                 # Gradients\n",
    "#                 dU = -np.dot(E, I) + l2_mu*U\n",
    "#                 dI = -np.dot(E.T, U) + l2_lambda*I\n",
    "#                 # Update velocity for U and V with momentum\n",
    "#                 v_U = (momentum * v_U) - (alpha * dU)\n",
    "#                 v_I = (momentum * v_I) - (alpha * dI)\n",
    "                \n",
    "#                 # Update U and V using momentum\n",
    "#                 U += v_U\n",
    "#                 I += v_I\n",
    "#                 # U -= alpha*dU\n",
    "#                 # I -= alpha*dI\n",
    "                \n",
    "#                 # Reset items in last columns to 1s.\n",
    "#                 U[:, -1] = 1\n",
    "#                 I[:, -2] = 1\n",
    "               \n",
    "                \n",
    "            \n",
    "#                 # # Check if validation loss improved\n",
    "#                 # if loss < best_validation_loss - tolerance:\n",
    "#                 #     best_validation_loss = loss\n",
    "#                 #     epochs_without_improvement = 0  # Reset patience counter\n",
    "#                 # else:\n",
    "#                 #     epochs_without_improvement += 1  # Increment patience counter\n",
    "            \n",
    "                \n",
    "            \n",
    "#                 # # Early stopping condition\n",
    "#                 # if epochs_without_improvement >= patience:\n",
    "#                 #     print(_)\n",
    "#                 #     break\n",
    "    \n",
    "            \n",
    "#             Rhat_train_final = np.where(S_train_finite, np.dot(U, I.T), 0)\n",
    "#             Rhat_test_final = np.where(S_test_finite, np.dot(U, I.T), 0)\n",
    "#             R_train_final = np.where(S_train_finite, np.nan_to_num(R), 0)\n",
    "#             R_test_final = np.where(S_test_finite, np.nan_to_num(R_test), 0)\n",
    "            \n",
    "#             training_RMSE = rmse(Rhat_train_final, R_train_final, S_train_finite)\n",
    "#             test_RMSE = rmse(Rhat_test_final, R_test_final, S_test_finite)\n",
    "#             RMSE_list.append(test_RMSE)\n",
    "#             test_RMSE_rounded = rmse(round_to_nearest_half(Rhat_test_final), R_test_final, S_test_finite)\n",
    "#             RMSE_list.append(test_RMSE_rounded)\n",
    "#             test_RMSE_fitted = rmse(fit_distribution(Rhat_test_final, R_test_final), R_test_final, S_test_finite)\n",
    "#             RMSE_list.append(test_RMSE_fitted)\n",
    "#             test_RMSE_fitted_rounded = rmse(round_to_nearest_half(fit_distribution(Rhat_test_final, R_test_final)), R_test_final, S_test_finite)\n",
    "#             RMSE_list.append(test_RMSE_fitted_rounded)\n",
    "#             test_RMSE_rounded_fitted = rmse(fit_distribution(round_to_nearest_half(Rhat_test_final), R_test_final), R_test_final, S_test_finite)\n",
    "#             RMSE_list.append(test_RMSE_rounded_fitted)\n",
    "#             print(\"k: \" + str(ia) + \", alpha: \" + str(ib))\n",
    "#             print(\"training RMSE: \" + str(training_RMSE))\n",
    "#             print(\"test RMSE: \" + str(test_RMSE))\n",
    "#             print(\"test RMSE rounded: \" + str(test_RMSE_rounded))\n",
    "#             print(\"test RMSE fitted: \" + str(test_RMSE_fitted))\n",
    "#             print(\"test RMSE fitted rounded: \" + str(test_RMSE_fitted_rounded))\n",
    "#             print(\"test RMSE rounded fitted: \" + str(test_RMSE_rounded_fitted))\n",
    "#             print(\"loss: \" + str(sum(losses)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(RMSE_list)\n",
    "# fig = sns.lineplot(RMSE_list)\n",
    "# plt.xlabel(\"alpha\")\n",
    "# plt.ylabel(\"RMSE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = sns.lineplot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.35211268 4.35211268 4.35211268 ... 4.35211268 4.35211268 4.35211268]\n",
      " [3.92857143 3.92857143 3.92857143 ... 3.92857143 3.92857143 3.92857143]\n",
      " [1.57692308 1.57692308 1.57692308 ... 1.57692308 1.57692308 1.57692308]\n",
      " ...\n",
      " [3.05576208 3.05576208 3.05576208 ... 3.05576208 3.05576208 3.05576208]\n",
      " [3.4375     3.4375     3.4375     ... 3.4375     3.4375     3.4375    ]\n",
      " [3.7414248  3.7414248  3.7414248  ... 3.7414248  3.7414248  3.7414248 ]]\n",
      "[[0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]]\n",
      "(610, 948)\n",
      "(4980, 948)\n",
      "[[4.35211268 4.35211268 4.35211268 ... 4.35211268 0.         1.        ]\n",
      " [3.92857143 3.92857143 3.92857143 ... 3.92857143 0.         1.        ]\n",
      " [1.57692308 1.57692308 1.57692308 ... 1.57692308 0.         1.        ]\n",
      " ...\n",
      " [3.05576208 3.05576208 3.05576208 ... 3.05576208 0.         1.        ]\n",
      " [3.4375     3.4375     3.4375     ... 3.4375     0.         1.        ]\n",
      " [3.7414248  3.7414248  3.7414248  ... 3.7414248  0.         1.        ]]\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c2ee69982a4057976e96789d56941b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 946, alpha: 8e-08\n",
      "training RMSE: 0.8013773052529161\n",
      "test RMSE: 0.9705623956757031\n",
      "test RMSE rounded: 1.014211629515705\n",
      "test RMSE fitted: 0.9621306977467662\n",
      "test RMSE fitted rounded: 1.0047989162413933\n",
      "test RMSE rounded fitted: 0.957549030634426\n",
      "loss: 16074.718296107598\n"
     ]
    }
   ],
   "source": [
    "# #intialization using word and user embeddings\n",
    "# U = users\n",
    "# I = tensor\n",
    "# print(U)\n",
    "# print(I)\n",
    "\n",
    "# empty_columns_1 = np.zeros((np.shape(U)[0], 2))\n",
    "# empty_columns_2 = np.zeros((np.shape(I)[0], 2))\n",
    "# U = np.hstack((U, empty_columns_1))\n",
    "# I = np.hstack((I, empty_columns_2))\n",
    "# print(np.shape(U))\n",
    "# print(np.shape(I))\n",
    "# v_U = np.zeros_like(U)\n",
    "# v_I = np.zeros_like(I)\n",
    "# U[:, -1] = 1\n",
    "# I[:, -2] = 1\n",
    "# print(U)\n",
    "# print(I)\n",
    "# losses = []\n",
    "# # Initialize variables for early stopping\n",
    "# best_validation_loss = float('inf')\n",
    "# epochs_without_improvement = 0\n",
    "# epochs = 1000\n",
    "# for _ in tqdm(range(epochs)):\n",
    "#     # Setting entries with no ratings to zero\n",
    "#     Rhat = np.dot(U, I.T)\n",
    "#     Rhat[S] = 0\n",
    "#     E = np.nan_to_num(R) - Rhat\n",
    "\n",
    "#     # Loss\n",
    "#     loss = np.sqrt(np.linalg.norm(E, 'fro'))\n",
    "#     losses.append(loss)\n",
    "#     #print(loss)\n",
    "\n",
    "#     # Gradients\n",
    "\n",
    "#     dU = -np.dot(E, I) + l2_mu*U\n",
    "#     dI = -np.dot(E.T, U) + l2_lambda*I\n",
    "    \n",
    "#     # Update velocity for U and V with momentum\n",
    "#     v_U = (momentum * v_U) - (alpha * dU)\n",
    "#     v_I = (momentum * v_I) - (alpha * dI)\n",
    "#     # Update U and V using momentum\n",
    "#     U += v_U\n",
    "#     I += v_I\n",
    "#     # U -= alpha*dU\n",
    "#     # I -= alpha*dI\n",
    "    \n",
    "#     # Reset items in last columns to 1s.\n",
    "#     U[:, -1] = 1\n",
    "#     I[:, -2] = 1\n",
    "#     # print(U)\n",
    "#     # print(I)\n",
    "    \n",
    "\n",
    "#     # # Check if validation loss improved\n",
    "#     # if loss < best_validation_loss - tolerance:\n",
    "#     #     best_validation_loss = loss\n",
    "#     #     epochs_without_improvement = 0  # Reset patience counter\n",
    "#     # else:\n",
    "#     #     epochs_without_improvement += 1  # Increment patience counter\n",
    "\n",
    "    \n",
    "\n",
    "#     # # Early stopping condition\n",
    "#     # if epochs_without_improvement >= patience:\n",
    "#     #     print(_)\n",
    "#     #     break\n",
    "\n",
    "\n",
    "# Rhat_train_final = np.where(S_train_finite, np.dot(U, I.T), 0)\n",
    "# Rhat_test_final = np.where(S_test_finite, np.dot(U, I.T), 0)\n",
    "# R_train_final = np.where(S_train_finite, np.nan_to_num(R), 0)\n",
    "# R_test_final = np.where(S_test_finite, np.nan_to_num(R_test), 0)\n",
    "\n",
    "# training_RMSE = rmse(Rhat_train_final, R_train_final, S_train_finite)\n",
    "# test_RMSE = rmse(Rhat_test_final, R_test_final, S_test_finite)\n",
    "# RMSE_list.append(test_RMSE)\n",
    "# test_RMSE_rounded = rmse(round_to_nearest_half(Rhat_test_final), R_test_final, S_test_finite)\n",
    "# RMSE_list.append(test_RMSE_rounded)\n",
    "# test_RMSE_fitted = rmse(fit_distribution(Rhat_test_final, R_test_final), R_test_final, S_test_finite)\n",
    "# RMSE_list.append(test_RMSE_fitted)\n",
    "# test_RMSE_fitted_rounded = rmse(round_to_nearest_half(fit_distribution(Rhat_test_final, R_test_final)), R_test_final, S_test_finite)\n",
    "# RMSE_list.append(test_RMSE_fitted_rounded)\n",
    "# test_RMSE_rounded_fitted = rmse(fit_distribution(round_to_nearest_half(Rhat_test_final), R_test_final), R_test_final, S_test_finite)\n",
    "# RMSE_list.append(test_RMSE_rounded_fitted)\n",
    "# print(\"k: \" + str(k) + \", alpha: \" + str(alpha))\n",
    "# print(\"training RMSE: \" + str(training_RMSE))\n",
    "# print(\"test RMSE: \" + str(test_RMSE))\n",
    "# print(\"test RMSE rounded: \" + str(test_RMSE_rounded))\n",
    "# print(\"test RMSE fitted: \" + str(test_RMSE_fitted))\n",
    "# print(\"test RMSE fitted rounded: \" + str(test_RMSE_fitted_rounded))\n",
    "# print(\"test RMSE rounded fitted: \" + str(test_RMSE_rounded_fitted))\n",
    "# print(\"loss: \" + str(sum(losses)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 375\n",
    "for _ in tqdm(range(epochs)):\n",
    "    # Setting entries with no ratings to zero\n",
    "    Rhat = np.dot(U, I.T)\n",
    "    Rhat[S] = 0\n",
    "    E = np.nan_to_num(R) - Rhat\n",
    "\n",
    "    # Loss\n",
    "    loss = np.sqrt(np.linalg.norm(E, 'fro'))\n",
    "    losses.append(loss)\n",
    "    #print(loss)\n",
    "\n",
    "    # Gradients\n",
    "\n",
    "    dU = -np.dot(E, I) + l2_mu*U\n",
    "    dI = -np.dot(E.T, U) + l2_lambda*I\n",
    "    \n",
    "    # Update velocity for U and V with momentum\n",
    "    v_U = (momentum * v_U) - (alpha * dU)\n",
    "    v_I = (momentum * v_I) - (alpha * dI)\n",
    "    # Update U and V using momentum\n",
    "    U += v_U\n",
    "    I += v_I\n",
    "    # U -= alpha*dU\n",
    "    # I -= alpha*dI\n",
    "    \n",
    "    # Reset items in last columns to 1s.\n",
    "    U[:, -1] = 1\n",
    "    I[:, -2] = 1\n",
    "    # print(U)\n",
    "    # print(I)\n",
    "    \n",
    "\n",
    "Rhat_train_final = np.where(S_train_finite, np.dot(U, I.T), 0)\n",
    "Rhat_test_final = np.where(S_test_finite, np.dot(U, I.T), 0)\n",
    "R_train_final = np.where(S_train_finite, np.nan_to_num(R), 0)\n",
    "R_test_final = np.where(S_test_finite, np.nan_to_num(R_test), 0)\n",
    "\n",
    "training_RMSE = rmse(Rhat_train_final, R_train_final, S_train_finite)\n",
    "test_RMSE = rmse(Rhat_test_final, R_test_final, S_test_finite)\n",
    "RMSE_list.append(test_RMSE)\n",
    "test_RMSE_rounded = rmse(round_to_nearest_half(Rhat_test_final), R_test_final, S_test_finite)\n",
    "RMSE_list.append(test_RMSE_rounded)\n",
    "test_RMSE_fitted = rmse(fit_distribution(Rhat_test_final, R_test_final), R_test_final, S_test_finite)\n",
    "RMSE_list.append(test_RMSE_fitted)\n",
    "test_RMSE_fitted_rounded = rmse(round_to_nearest_half(fit_distribution(Rhat_test_final, R_test_final)), R_test_final, S_test_finite)\n",
    "RMSE_list.append(test_RMSE_fitted_rounded)\n",
    "test_RMSE_rounded_fitted = rmse(fit_distribution(round_to_nearest_half(Rhat_test_final), R_test_final), R_test_final, S_test_finite)\n",
    "RMSE_list.append(test_RMSE_rounded_fitted)\n",
    "print(\"k: \" + str(k) + \", alpha: \" + str(alpha))\n",
    "print(\"training RMSE: \" + str(training_RMSE))\n",
    "print(\"test RMSE: \" + str(test_RMSE))\n",
    "print(\"test RMSE rounded: \" + str(test_RMSE_rounded))\n",
    "print(\"test RMSE fitted: \" + str(test_RMSE_fitted))\n",
    "print(\"test RMSE fitted rounded: \" + str(test_RMSE_fitted_rounded))\n",
    "print(\"test RMSE rounded fitted: \" + str(test_RMSE_rounded_fitted))\n",
    "print(\"loss: \" + str(sum(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
